# src/config_manager/core/file_operations.py
from __future__ import annotations
from datetime import datetime

import os
import logging
from ruamel.yaml import YAML
from typing import Dict, Any, Optional
from ..utils import lock_file, unlock_file

logger = logging.getLogger(__name__)


class FileOperations:
    """æ–‡ä»¶æ“ä½œç®¡ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ–‡ä»¶æ“ä½œç®¡ç†å™¨"""
        # åˆ›å»ºYAMLå®ä¾‹ï¼Œé…ç½®ä¸ºä¿ç•™æ³¨é‡Šå’Œæ ¼å¼
        self._yaml = YAML()
        self._yaml.preserve_quotes = True
        self._yaml.map_indent = 2
        self._yaml.sequence_indent = 4
        self._yaml.sequence_dash_offset = 2
        self._yaml.default_flow_style = False

        # å­˜å‚¨åŸå§‹YAMLç»“æ„ä»¥ä¿ç•™æ³¨é‡Š
        self._original_yaml_data = None
        self._config_path = None
        return

    def load_config(self, config_path: str, auto_create: bool, call_chain_tracker) -> Optional[Dict]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        # æ£€æŸ¥è°ƒç”¨é“¾æ˜¾ç¤ºå¼€å…³
        from ..config_manager import ENABLE_CALL_CHAIN_DISPLAY

        if not os.path.exists(config_path):
            if auto_create:
                print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é…ç½®: {config_path}")

                # æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦æ˜¾ç¤ºè°ƒç”¨é“¾
                if ENABLE_CALL_CHAIN_DISPLAY:
                    try:
                        call_chain = call_chain_tracker.get_call_chain()
                        print(f"åˆ›å»ºé…ç½®è°ƒç”¨é“¾: {call_chain}")
                    except Exception as e:
                        print(f"è·å–åˆ›å»ºè°ƒç”¨é“¾å¤±è´¥: {e}")

                # åˆ›å»ºç©ºé…ç½®å¹¶ä¿å­˜
                empty_data = {'__data__': {}, '__type_hints__': {}}
                self.save_config(config_path, empty_data)
                return empty_data
            else:
                print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return None

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                lock_file(f)
                try:
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    content = f.read()

                    # å¤„ç†Windowsè·¯å¾„ä¸­çš„åæ–œæ è½¬ä¹‰é—®é¢˜
                    import re
                    def fix_windows_path(match):
                        path = match.group(1)
                        # å°†åŒåæ–œæ æ›¿æ¢ä¸ºå•æ–œæ ï¼Œé¿å…è½¬ä¹‰é—®é¢˜
                        # å…ˆå¤„ç†åŒåæ–œæ ï¼ˆ\\\\ï¼‰ï¼Œå†å¤„ç†å•åæ–œæ ï¼ˆ\\ï¼‰
                        fixed_path = path.replace('\\\\', '/').replace('\\', '/')
                        return f'"{fixed_path}"'

                    # ä¿®å¤å¸¸è§çš„Windowsè·¯å¾„è½¬ä¹‰é—®é¢˜
                    # åŒ¹é…åŒå¼•å·ä¸­çš„Windowsè·¯å¾„ï¼ˆåŒ…æ‹¬ç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ï¼‰
                    content = re.sub(r'"([a-zA-Z]:[\\\\][^"]*)"', fix_windows_path, content)
                    content = re.sub(r'"([\\\\][^"]*)"', fix_windows_path, content)  # ä»¥åæ–œæ å¼€å¤´çš„è·¯å¾„
                    content = re.sub(r'"(\.[\\\\][^"]*)"', fix_windows_path, content)  # ç›¸å¯¹è·¯å¾„å¦‚ ".\\logs"

                    # åŠ è½½ä¿®å¤åçš„YAMLæ•°æ®
                    loaded_data = self._yaml.load(content) or {}
                    
                    # éªŒè¯YAMLæ•°æ®ç±»å‹çš„æ­£ç¡®æ€§
                    self._validate_yaml_types(loaded_data, config_path)

                    # ä¿å­˜åŸå§‹YAMLç»“æ„å’Œè·¯å¾„ï¼Œç”¨äºåç»­ä¿å­˜æ—¶ä¿ç•™æ³¨é‡Š
                    self._original_yaml_data = loaded_data
                    self._config_path = config_path
                finally:
                    unlock_file(f)

            # æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦æ˜¾ç¤ºåŠ è½½è°ƒç”¨é“¾
            print(f"é…ç½®å·²ä» {config_path} åŠ è½½")
            if ENABLE_CALL_CHAIN_DISPLAY:
                try:
                    call_chain = call_chain_tracker.get_call_chain()
                    print(f"åŠ è½½é…ç½®è°ƒç”¨é“¾: {call_chain}")
                except Exception as e:
                    print(f"è·å–åŠ è½½è°ƒç”¨é“¾å¤±è´¥: {e}")
                    # å°è¯•è·å–è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                    try:
                        debug_info = call_chain_tracker.get_detailed_call_info()
                        print(f"è°ƒç”¨é“¾è°ƒè¯•ä¿¡æ¯: {debug_info}")
                    except Exception as debug_e:
                        print(f"è·å–è°ƒè¯•ä¿¡æ¯ä¹Ÿå¤±è´¥: {debug_e}")

            return loaded_data
        except TypeError:
            # ç±»å‹éªŒè¯é”™è¯¯åº”è¯¥ç›´æ¥æŠ›å‡ºï¼Œä¸è¦æ•è·
            raise
        except Exception as e:
            print(f"âš ï¸  YAMLè§£æå¤±è´¥: {str(e)}")
            print("âš ï¸  ä¸ºä¿æŠ¤åŸå§‹é…ç½®æ–‡ä»¶ï¼Œä¸ä¼šè‡ªåŠ¨åˆ›å»ºæ–°é…ç½®")
            print("âš ï¸  è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼ï¼Œç‰¹åˆ«æ˜¯Windowsè·¯å¾„ä¸­çš„åæ–œæ ")
            return None

    def save_config(self, config_path: str, data: Dict[str, Any], backup_path: str = None) -> bool:
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶ï¼Œä¿ç•™æ³¨é‡Šå’Œæ ¼å¼å¹¶å½»åº•è§£å†³é‡å¤é”®é—®é¢˜"""
        try:
            # ä¿å­˜åˆ°ä¸»é…ç½®æ–‡ä»¶
            original_dir = os.path.dirname(config_path)
            if original_dir:
                os.makedirs(original_dir, exist_ok=True)

            # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
            data_to_save = self._prepare_data_for_save(config_path, data)

            tmp_original_path = f"{config_path}.tmp"
            with open(tmp_original_path, 'w', encoding='utf-8') as f:
                self._yaml.dump(data_to_save, f)

            # åå¤„ç†ï¼šåˆ é™¤YAMLæ–‡ä»¶ä¸­çš„é‡å¤é”®
            self._remove_duplicate_keys_from_yaml_file(tmp_original_path)

            os.replace(tmp_original_path, config_path)

            # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœæä¾›äº†å¤‡ä»½è·¯å¾„ï¼‰
            if backup_path:
                try:
                    backup_dir = os.path.dirname(backup_path)
                    if backup_dir:
                        os.makedirs(backup_dir, exist_ok=True)

                    tmp_backup_path = f"{backup_path}.tmp"
                    with open(tmp_backup_path, 'w', encoding='utf-8') as f:
                        self._yaml.dump(data_to_save, f)

                    os.replace(tmp_backup_path, backup_path)
                    print(f"é…ç½®å·²è‡ªåŠ¨å¤‡ä»½åˆ° {backup_path}")
                except Exception as backup_error:
                    print(f"å¤‡ä»½ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ä¸»é…ç½®æ–‡ä»¶ï¼‰: {str(backup_error)}")

            return True
        except Exception as e:
            print(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
            return False

    def save_config_only(self, config_path: str, data: Dict[str, Any]) -> bool:
        """ä»…ä¿å­˜é…ç½®åˆ°ä¸»æ–‡ä»¶ï¼Œä¸åˆ›å»ºå¤‡ä»½"""
        try:
            # ä¿å­˜åˆ°ä¸»é…ç½®æ–‡ä»¶
            original_dir = os.path.dirname(config_path)
            if original_dir:
                os.makedirs(original_dir, exist_ok=True)

            # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
            data_to_save = self._prepare_data_for_save(config_path, data)

            tmp_original_path = f"{config_path}.tmp"
            with open(tmp_original_path, 'w', encoding='utf-8') as f:
                self._yaml.dump(data_to_save, f)

            os.replace(tmp_original_path, config_path)
            return True
        except Exception as e:
            print(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
            return False

    def create_backup_only(self, backup_path: str, data: Dict[str, Any]) -> bool:
        """ä»…åˆ›å»ºå¤‡ä»½æ–‡ä»¶ï¼Œä¸ä¿å­˜ä¸»é…ç½®"""
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            backup_dir = os.path.dirname(backup_path)
            if backup_dir:
                os.makedirs(backup_dir, exist_ok=True)

            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ•°æ®åˆ›å»ºå¤‡ä»½ï¼ˆä¸éœ€è¦å‡†å¤‡æ•°æ®ï¼Œå› ä¸ºä¸æ¶‰åŠä¸»é…ç½®æ–‡ä»¶ï¼‰
            tmp_backup_path = f"{backup_path}.tmp"
            with open(tmp_backup_path, 'w', encoding='utf-8') as f:
                self._yaml.dump(data, f)

            os.replace(tmp_backup_path, backup_path)
            return True
        except Exception as e:
            print(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {str(e)}")
            return False

    def _prepare_data_for_save(self, config_path: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®ï¼Œå°½å¯èƒ½ä¿ç•™åŸå§‹ç»“æ„å’Œæ³¨é‡Š"""
        # å¦‚æœæœ‰åŸå§‹YAMLæ•°æ®ä¸”è·¯å¾„åŒ¹é…ï¼Œåˆ™æ›´æ–°åŸå§‹ç»“æ„
        if (self._original_yaml_data is not None and
                self._config_path == config_path and
                isinstance(self._original_yaml_data, dict)):

            # æ·±åº¦æ›´æ–°åŸå§‹æ•°æ®ç»“æ„
            updated_data = self._deep_update_yaml_data(self._original_yaml_data.copy(), data)
            return updated_data
        else:
            # æ²¡æœ‰åŸå§‹ç»“æ„ï¼Œä½†å¦‚æœè·¯å¾„ä¸åŒï¼Œå°è¯•é‡æ–°åŠ è½½åŸå§‹æ•°æ®
            if config_path != self._config_path:
                self._try_reload_original_data(config_path)
                # é‡æ–°å°è¯•æ›´æ–°
                if (self._original_yaml_data is not None and
                        isinstance(self._original_yaml_data, dict)):
                    updated_data = self._deep_update_yaml_data(self._original_yaml_data.copy(), data)
                    return updated_data
            
            # æ²¡æœ‰åŸå§‹ç»“æ„ï¼Œç›´æ¥è¿”å›æ–°æ•°æ®
            return data

    def _deep_update_yaml_data(self, original: Any, new_data: Any) -> Any:
        """æ·±åº¦æ›´æ–°YAMLæ•°æ®ï¼Œä¿ç•™åŸå§‹ç»“æ„å’Œæ³¨é‡Š"""
        if isinstance(original, dict) and isinstance(new_data, dict):
            # æ£€æµ‹æ˜¯å¦æ˜¯åŸå§‹æ ¼å¼åˆ°æ ‡å‡†æ ¼å¼çš„è½¬æ¢
            is_raw_to_standard = ('__data__' not in original and '__data__' in new_data)
            
            if is_raw_to_standard:
                # ç‰¹æ®Šå¤„ç†ï¼šåŸå§‹æ ¼å¼è½¬æ ‡å‡†æ ¼å¼ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥ä¿ç•™æ³¨é‡Š
                # print("ğŸ”§ æ£€æµ‹åˆ°åŸå§‹æ ¼å¼åˆ°æ ‡å‡†æ ¼å¼è½¬æ¢ï¼Œé‡‡ç”¨æ³¨é‡Šä¿ç•™ç­–ç•¥")
                return self._convert_raw_to_standard_preserving_comments(original, new_data)
            else:
                # æ ‡å‡†çš„æ·±åº¦åˆå¹¶ï¼Œä¿ç•™ruamel.yamlçš„æ³¨é‡Šä¿¡æ¯
                for key, value in new_data.items():
                    if key in original and isinstance(original[key], dict) and isinstance(value, dict):
                        # é€’å½’åˆå¹¶åµŒå¥—å­—å…¸
                        self._deep_update_yaml_data(original[key], value)
                    else:
                        # ç›´æ¥æ›´æ–°å€¼ï¼ˆåŒ…æ‹¬æ–°é”®ï¼‰
                        original[key] = value
                
                # ç§»é™¤é¡¶å±‚é‡å¤é”®
                if '__data__' in new_data and isinstance(new_data['__data__'], dict):
                    self._remove_all_duplicate_keys_from_top_level(original, new_data['__data__'])
            
            return original
        elif isinstance(original, list) and isinstance(new_data, list):
            # å¯¹äºåˆ—è¡¨ï¼Œç›´æ¥æ›¿æ¢ï¼ˆä¿æŒç®€å•ï¼‰
            return new_data
        else:
            # å¯¹äºå…¶ä»–ç±»å‹ï¼Œç›´æ¥æ›¿æ¢
            return new_data
    
    def _convert_raw_to_standard_preserving_comments(self, original: dict, new_data: dict) -> dict:
        """å°†åŸå§‹æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæœ€å¤§ç¨‹åº¦ä¿ç•™æ³¨é‡Š"""
        # ç­–ç•¥ï¼šä¿æŒåŸå§‹ç»“æ„ï¼Œåªæ›´æ–°å€¼ï¼Œåœ¨æœ«å°¾æ·»åŠ æ–°èŠ‚ç‚¹
        
        # è·å–æ–°æ•°æ®ä¸­çš„ __data__ å†…å®¹
        data_section = new_data.get('__data__', {})
        type_hints_section = new_data.get('__type_hints__', {})
        
        # æ›´æ–°åŸå§‹ç»“æ„ä¸­å·²å­˜åœ¨çš„é”®å€¼
        for key, value in data_section.items():
            if key in original:
                if isinstance(original[key], dict) and isinstance(value, dict):
                    # é€’å½’æ›´æ–°åµŒå¥—å­—å…¸
                    self._deep_update_yaml_data(original[key], value)
                else:
                    # æ›´æ–°å€¼
                    original[key] = value
        
        # æ·»åŠ æ–°çš„é”®åˆ°åŸå§‹ç»“æ„ï¼ˆè¿™äº›é”®åœ¨åŸå§‹æ–‡ä»¶ä¸­ä¸å­˜åœ¨ï¼Œä½†æ’é™¤ç³»ç»Ÿé”®ï¼‰
        system_keys = {'__data__', '__type_hints__'}
        for key, value in data_section.items():
            if key not in original and key not in system_keys:
                original[key] = value
        
        # åœ¨æœ«å°¾æ·»åŠ  __data__ èŠ‚ç‚¹ï¼ˆåªåŒ…å«éç³»ç»Ÿé”®çš„é…ç½®æ•°æ®ï¼‰
        # è¿‡æ»¤æ‰ç³»ç»Ÿé”®ï¼Œé¿å…æ•°æ®ç»“æ„æ±¡æŸ“
        system_keys = {'__data__', '__type_hints__'}
        clean_data_section = {k: v for k, v in data_section.items() if k not in system_keys}
        original['__data__'] = clean_data_section
        
        # æ·»åŠ  __type_hints__ èŠ‚ç‚¹
        if type_hints_section:
            original['__type_hints__'] = type_hints_section
        elif '__type_hints__' not in original:
            original['__type_hints__'] = {}
        
        # print(f"ğŸ”§ åŸå§‹æ ¼å¼è½¬æ¢å®Œæˆï¼Œä¿ç•™äº†åŸå§‹é”®é¡ºåºå’Œæ³¨é‡Š")
        return original
    
    def _is_anchor_alias_reference(self, original_data: dict, key: str, value: Any) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯é”šç‚¹åˆ«åå¼•ç”¨æƒ…å†µ
        
        Args:
            original_data: åŸå§‹YAMLæ•°æ®
            key: è¦æ£€æŸ¥çš„é”®å
            value: __data__ä¸­çš„å€¼
            
        Returns:
            bool: å¦‚æœæ˜¯é”šç‚¹åˆ«åå¼•ç”¨æƒ…å†µè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        # æ£€æŸ¥é¡¶å±‚æ˜¯å¦å­˜åœ¨è¯¥é”®
        if key not in original_data:
            return False
        
        original_value = original_data[key]
        
        # å¦‚æœä¸¤ä¸ªå€¼å®Œå…¨ç›¸åŒï¼ˆåŒ…æ‹¬å¼•ç”¨å…³ç³»ï¼‰ï¼Œæ˜¯é”šç‚¹åˆ«åæƒ…å†µ
        if original_value is value:
            return True
        
        # å¯¹äºå­—å…¸ç±»å‹ï¼Œéœ€è¦æ·±åº¦æ£€æŸ¥æ˜¯å¦å­˜åœ¨é”šç‚¹åˆ«åå¼•ç”¨çš„å­é”®
        if isinstance(value, dict) and isinstance(original_value, dict):
            return self._has_anchor_alias_subkeys(original_value, value)
        
        # å¦‚æœå€¼å†…å®¹ç›¸åŒä½†ä¸æ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œä¹Ÿå¯èƒ½æ˜¯é”šç‚¹åˆ«åå±•å¼€çš„ç»“æœ
        if original_value == value:
            # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦ä¸ºå¤æ‚æ•°æ®ç»“æ„ï¼ˆå­—å…¸æˆ–åˆ—è¡¨ï¼‰
            # å¯¹äºç®€å•å€¼ï¼Œç›¸ç­‰ä¸ä¸€å®šæ„å‘³ç€é”šç‚¹åˆ«å
            if isinstance(value, (dict, list)) and len(str(value)) > 10:
                return True
        
        return False
    
    def _has_anchor_alias_subkeys(self, original_dict: dict, data_dict: dict) -> bool:
        """æ£€æŸ¥å­—å…¸ä¸­æ˜¯å¦åŒ…å«é”šç‚¹åˆ«åå¼•ç”¨çš„å­é”®
        
        Args:
            original_dict: é¡¶å±‚åŸå§‹å­—å…¸
            data_dict: __data__ä¸­çš„å­—å…¸
            
        Returns:
            bool: å¦‚æœåŒ…å«é”šç‚¹åˆ«åå¼•ç”¨çš„å­é”®è¿”å›True
        """
        # æ£€æŸ¥data_dictä¸­çš„æ¯ä¸ªé”®æ˜¯å¦åœ¨original_dictä¸­ä½œä¸ºé”šç‚¹åˆ«åå¼•ç”¨å­˜åœ¨
        for sub_key, sub_value in data_dict.items():
            if sub_key in original_dict:
                original_sub_value = original_dict[sub_key]
                
                # å¦‚æœæ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œè¯´æ˜å­˜åœ¨é”šç‚¹åˆ«åå¼•ç”¨
                if original_sub_value is sub_value:
                    return True
                
                # é€’å½’æ£€æŸ¥åµŒå¥—å­—å…¸
                if isinstance(sub_value, dict) and isinstance(original_sub_value, dict):
                    if self._has_anchor_alias_subkeys(original_sub_value, sub_value):
                        return True
        
        return False
    
    def _has_any_anchor_alias_references(self, original_data: dict, data_section: dict) -> bool:
        """æ£€æŸ¥__data__éƒ¨åˆ†æ˜¯å¦åŒ…å«ä»»ä½•é”šç‚¹åˆ«åå¼•ç”¨
        
        Args:
            original_data: åŸå§‹YAMLæ•°æ®ï¼ˆé¡¶å±‚ï¼‰
            data_section: __data__éƒ¨åˆ†çš„æ•°æ®
            
        Returns:
            bool: å¦‚æœåŒ…å«ä»»ä½•é”šç‚¹åˆ«åå¼•ç”¨è¿”å›True
        """
        for key, value in data_section.items():
            # è·³è¿‡ç³»ç»Ÿå­—æ®µå’Œå†…éƒ¨é”®
            if key.startswith('__'):
                continue
                
            # æ£€æŸ¥è¯¥é”®æ˜¯å¦åœ¨é¡¶å±‚å­˜åœ¨é”šç‚¹åˆ«åå¼•ç”¨
            if key in original_data:
                if self._is_anchor_alias_reference(original_data, key, value):
                    return True
        
        return False
    
    def _remove_top_level_anchor_alias_keys(self, original_data: dict, data_section: dict) -> None:
        """ç§»é™¤é¡¶å±‚çš„é”šç‚¹åˆ«åå¼•ç”¨é”®ä»¥é¿å…é‡å¤
        
        Args:
            original_data: åŸå§‹YAMLæ•°æ®ï¼ˆé¡¶å±‚ï¼‰
            data_section: __data__éƒ¨åˆ†çš„æ•°æ®
        """
        keys_to_remove = []
        
        for key, value in data_section.items():
            # è·³è¿‡ç³»ç»Ÿå­—æ®µå’Œå†…éƒ¨é”®
            if key.startswith('__'):
                continue
                
            # æ£€æŸ¥è¯¥é”®æ˜¯å¦åœ¨é¡¶å±‚å­˜åœ¨é”šç‚¹åˆ«åå¼•ç”¨
            if key in original_data:
                if self._is_anchor_alias_reference(original_data, key, value):
                    keys_to_remove.append(key)
                elif isinstance(value, dict) and isinstance(original_data[key], dict):
                    # å¯¹äºå­—å…¸ç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«é”šç‚¹åˆ«åå¼•ç”¨çš„å­é”®
                    if self._has_anchor_alias_subkeys(original_data[key], value):
                        keys_to_remove.append(key)
        
        # ç§»é™¤æ£€æµ‹åˆ°çš„é”šç‚¹åˆ«åå¼•ç”¨é”®
        for key in keys_to_remove:
            del original_data[key]
    
    def _remove_all_duplicate_keys_from_top_level(self, original_data: dict, data_section: dict) -> None:
        """ç§»é™¤YAMLé”šç‚¹åˆ«åå±•å¼€äº§ç”Ÿçš„é‡å¤é”®ï¼Œä¿ç•™é”šç‚¹å®šä¹‰
        
        ä¸“é—¨å¤„ç†YAMLé”šç‚¹åˆ«å(&id001, *id001)å±•å¼€äº§ç”Ÿçš„é‡å¤é”®ï¼š
        - ä¿ç•™é”šç‚¹å®šä¹‰ï¼ˆ__data__ä¸­çš„ï¼Œç¬¬1ä¸ªï¼‰
        - åˆ é™¤åˆ«åå±•å¼€ï¼ˆé¡¶å±‚çš„ï¼Œç¬¬2ä¸ªåŠåç»­ï¼‰
        - å…¶ä»–éé”šç‚¹ç›¸å…³çš„é‡å¤é”®ä¸åˆ é™¤ï¼Œå¯èƒ½æœ‰ç‰¹æ®Šç”¨é€”
        
        Args:
            original_data: åŸå§‹YAMLæ•°æ®ï¼ˆé¡¶å±‚ï¼‰
            data_section: __data__éƒ¨åˆ†çš„æ•°æ®
        """
        keys_to_remove = []
        
        # å®šä¹‰å¿…é¡»ä¿ç•™çš„é¡¶å±‚ç³»ç»Ÿé”®
        protected_top_level_keys = {'__data__', '__type_hints__'}
        
        for key in list(original_data.keys()):
            # ä¿æŠ¤ç³»ç»Ÿé”®ä¸è¢«ç§»é™¤
            if key in protected_top_level_keys:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åœ¨__data__ä¸­å­˜åœ¨
            if key in data_section:
                top_level_value = original_data[key]
                data_section_value = data_section[key]
                
                # åªæœ‰å½“å€¼å®Œå…¨ç›¸åŒæ—¶æ‰å¯èƒ½æ˜¯é”šç‚¹åˆ«åå±•å¼€äº§ç”Ÿçš„é‡å¤
                if self._are_values_identical(top_level_value, data_section_value):
                    # è¿™æ˜¯é”šç‚¹åˆ«åå±•å¼€äº§ç”Ÿçš„é‡å¤ï¼š
                    # ä¿ç•™é”šç‚¹å®šä¹‰(__data__ä¸­çš„ï¼Œç¬¬1ä¸ª)ï¼Œåˆ é™¤åˆ«åå±•å¼€(é¡¶å±‚çš„ï¼Œç¬¬2ä¸ª)
                    keys_to_remove.append(key)
                    print(f"åˆ é™¤é”šç‚¹åˆ«åå±•å¼€é‡å¤: '{key}' (ä¿ç•™__data__ä¸­çš„é”šç‚¹å®šä¹‰)")
                else:
                    # å€¼ä¸åŒï¼Œä¿ç•™é¡¶å±‚çš„é”®ï¼ˆéé”šç‚¹åˆ«åé‡å¤ï¼Œå¯èƒ½æœ‰ç‰¹æ®Šç”¨é€”ï¼‰
                    print(f"ä¿ç•™é¡¶å±‚é”® '{key}': å€¼ä¸__data__ä¸­çš„ä¸åŒï¼Œéé”šç‚¹åˆ«åé‡å¤")
        
        # ç§»é™¤ç¡®è®¤çš„é”šç‚¹åˆ«åé‡å¤é”®
        for key in keys_to_remove:
            del original_data[key]
            
        # è®°å½•ç§»é™¤çš„é”®ç”¨äºè°ƒè¯•
        if keys_to_remove:
            print(f"ç§»é™¤é”šç‚¹åˆ«åé‡å¤é”®: {keys_to_remove}")
        else:
            print("æœªå‘ç°é”šç‚¹åˆ«åé‡å¤é”®éœ€è¦åˆ é™¤")
    
    def _are_values_identical(self, value1: Any, value2: Any) -> bool:
        """æ¯”è¾ƒä¸¤ä¸ªå€¼æ˜¯å¦å®Œå…¨ç›¸åŒï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºçœŸæ­£çš„é‡å¤
        
        Args:
            value1: ç¬¬ä¸€ä¸ªå€¼
            value2: ç¬¬äºŒä¸ªå€¼
            
        Returns:
            bool: å¦‚æœå€¼å®Œå…¨ç›¸åŒè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªå¯¹è±¡å¼•ç”¨ï¼ˆé”šç‚¹åˆ«åæƒ…å†µï¼‰
            if value1 is value2:
                return True
            
            # æ£€æŸ¥åŸºæœ¬ç±»å‹çš„ç›¸ç­‰æ€§
            if type(value1) is not type(value2):
                return False
            
            # å¯¹äºå­—å…¸ç±»å‹ï¼Œé€’å½’æ¯”è¾ƒ
            if isinstance(value1, dict) and isinstance(value2, dict):
                if set(value1.keys()) != set(value2.keys()):
                    return False
                for key in value1.keys():
                    if not self._are_values_identical(value1[key], value2[key]):
                        return False
                return True
            
            # å¯¹äºåˆ—è¡¨ç±»å‹ï¼Œé€ä¸€æ¯”è¾ƒå…ƒç´ 
            if isinstance(value1, list) and isinstance(value2, list):
                if len(value1) != len(value2):
                    return False
                for i in range(len(value1)):
                    if not self._are_values_identical(value1[i], value2[i]):
                        return False
                return True
            
            # å¯¹äºåŸºæœ¬ç±»å‹ï¼Œç›´æ¥æ¯”è¾ƒå€¼
            return value1 == value2
            
        except Exception:
            # æ¯”è¾ƒå‡ºç°å¼‚å¸¸æ—¶ï¼Œä¿å®ˆèµ·è§è®¤ä¸ºä¸ç›¸åŒ
            return False
    
    def _remove_duplicate_keys_from_yaml_file(self, file_path: str) -> None:
        """ç›´æ¥ç¼–è¾‘YAMLæ–‡ä»¶ï¼Œåˆ é™¤é‡å¤é”®ï¼Œç‰¹åˆ«å¤„ç†__data__å’Œé¡¶å±‚çš„é‡å¤æƒ…å†µ"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œå¦‚æœæ˜¯åˆ™å‡å°‘è¯¦ç»†æ—¥å¿—è¾“å‡º
        is_test_mode = '/tests/' in file_path or '/tmp/' in file_path
        # if not is_test_mode:
        #     print(f"ğŸ”§ å¼€å§‹YAMLæ–‡ä»¶åå¤„ç†: {file_path}")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # if not is_test_mode:
            #     print(f"ğŸ”§ è¯»å–åˆ° {len(lines)} è¡Œå†…å®¹")
            
            # è®°å½•é”®çš„å‡ºç°æƒ…å†µï¼šé”®å -> [(è¡Œå·, å±‚çº§, æ‰€åœ¨æ®µ)]
            key_occurrences = {}
            lines_to_remove = set()
            current_section = None
            protected_keys = {'__data__', '__type_hints__'}
            
            # ç¬¬ä¸€è½®ï¼šæ”¶é›†æ‰€æœ‰é”®çš„å‡ºç°ä¿¡æ¯ï¼Œæ„å»ºå®Œæ•´çš„å±‚çº§è·¯å¾„
            path_stack = []  # ç»´æŠ¤å½“å‰çš„è·¯å¾„æ ˆ
            for i, line in enumerate(lines):
                stripped_line = line.strip()
                
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                if not stripped_line or stripped_line.startswith('#'):
                    continue
                
                # å¦‚æœè¡ŒåŒ…å«å†’å·ï¼Œæå–é”®å
                if ':' in stripped_line:
                    # è®¡ç®—ç¼©è¿›çº§åˆ«
                    indent_level = len(line) - len(line.lstrip())
                    key = stripped_line.split(':')[0].strip()
                    
                    # è·³è¿‡é”šç‚¹å’Œåˆ«åå®šä¹‰è¡Œ
                    if '&' in key or '*' in key:
                        # if not is_test_mode:
                        #     print(f"ğŸ”§ è·³è¿‡é”šç‚¹/åˆ«åé”®: {key} (ç¬¬{i+1}è¡Œ)")
                        continue
                    
                    # æ£€æŸ¥å€¼éƒ¨åˆ†æ˜¯å¦åŒ…å«åˆ«åå¼•ç”¨
                    colon_pos = stripped_line.find(':')
                    if colon_pos != -1 and colon_pos + 1 < len(stripped_line):
                        value_part = stripped_line[colon_pos + 1:].strip()
                        if value_part.startswith('*'):
                            # if not is_test_mode:
                            #     print(f"ğŸ”§ è·³è¿‡åˆ«åå¼•ç”¨: {key}: {value_part} (ç¬¬{i+1}è¡Œ)")
                            continue
                    
                    # æ ¹æ®ç¼©è¿›çº§åˆ«è°ƒæ•´è·¯å¾„æ ˆ
                    target_depth = indent_level // 2  # å‡è®¾æ¯çº§ç¼©è¿›2ä¸ªç©ºæ ¼
                    path_stack = path_stack[:target_depth]
                    path_stack.append(key)
                    
                    # æ„å»ºå®Œæ•´çš„é”®è·¯å¾„
                    full_key_path = '.'.join(path_stack)
                    
                    # æ›´æ–°å½“å‰æ®µï¼ˆåªç”¨äºå‘åå…¼å®¹ï¼‰
                    if indent_level == 0:
                        current_section = key
                    
                    # ä½¿ç”¨å®Œæ•´è·¯å¾„ä½œä¸ºé”®æ ‡è¯†
                    if full_key_path not in key_occurrences:
                        key_occurrences[full_key_path] = []
                    
                    key_occurrences[full_key_path].append((i, indent_level, current_section, key))
                    # if not is_test_mode:
                    #     print(f"ğŸ”§ å‘ç°é”®è·¯å¾„: '{full_key_path}' -> '{key}' (ç¬¬{i+1}è¡Œ, ç¼©è¿›{indent_level})")
            
            # ç¬¬äºŒè½®ï¼šåˆ†æé‡å¤æƒ…å†µå¹¶æ ‡è®°åˆ é™¤
            for full_key_path, occurrences in key_occurrences.items():
                if len(occurrences) <= 1:
                    continue  # æ²¡æœ‰é‡å¤
                
                # æå–åŸºç¡€é”®åï¼ˆè·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ï¼‰
                base_key = full_key_path.split('.')[-1]
                
                # è·³è¿‡å—ä¿æŠ¤çš„ç³»ç»Ÿé”®åœ¨é¡¶å±‚çš„ä¿æŠ¤
                if base_key in protected_keys:
                    # ä½†æ˜¯è¦æ£€æŸ¥æ˜¯å¦æœ‰__data__å†…éƒ¨å’Œé¡¶å±‚çš„é‡å¤
                    data_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                      if section == '__data__' and indent > 0]
                    top_level_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                           if indent == 0 and section != '__data__']
                    
                    if data_occurrences and top_level_occurrences:
                        # __data__å†…éƒ¨å’Œé¡¶å±‚éƒ½æœ‰__type_hints__ï¼Œåˆ é™¤__data__å†…éƒ¨çš„ï¼ˆè¿™æ˜¯æ•°æ®ç»“æ„æ±¡æŸ“ï¼‰
                        for line_no, indent, section, key in data_occurrences:
                            lines_to_remove.add(line_no)
                            self._mark_key_block_for_removal(lines, line_no, indent, lines_to_remove)
                            # print(f"âŒ åˆ é™¤__data__å†…éƒ¨çš„ç³»ç»Ÿé”®: {key} (ç¬¬{line_no+1}è¡Œ) - ä¿ç•™é¡¶å±‚ç‰ˆæœ¬ï¼Œä¿®å¤æ•°æ®ç»“æ„æ±¡æŸ“")
                    continue
                
                # print(f"ğŸ”§ åˆ†æé‡å¤è·¯å¾„ '{full_key_path}': {len(occurrences)} æ¬¡å‡ºç°")
                
                # ç‰¹æ®Šå¤„ç†first_start_timeï¼šå¦‚æœå‡ºç°åœ¨__data__ç›´æ¥å­å±‚å’Œ__data__.__type_hints__ä¸­ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                if base_key == 'first_start_time':
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®å€¼å’Œç±»å‹æç¤ºçš„åˆç†ç»„åˆ
                    data_value_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                            if section == '__data__' and indent == 2]
                    type_hint_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                           if section == '__data__' and indent == 4]
                    top_level_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                           if indent == 0 and section != '__data__']
                    
                    # print(f"ğŸ”§ first_start_timeåˆ†æ: æ•°æ®å€¼{len(data_value_occurrences)}ä¸ª, ç±»å‹æç¤º{len(type_hint_occurrences)}ä¸ª, é¡¶å±‚{len(top_level_occurrences)}ä¸ª")
                    
                    # åˆ é™¤é¡¶å±‚çš„first_start_timeï¼Œä¿ç•™__data__ä¸­çš„æ•°æ®å€¼å’Œç±»å‹æç¤º
                    if top_level_occurrences:
                        for line_no, indent, section, key in top_level_occurrences:
                            lines_to_remove.add(line_no)
                            self._mark_key_block_for_removal(lines, line_no, indent, lines_to_remove)
                            # print(f"âŒ åˆ é™¤é¡¶å±‚é‡å¤é”®: {key} (ç¬¬{line_no+1}è¡Œ) - ä¿ç•™__data__ä¸­çš„ç‰ˆæœ¬")
                    
                    # å¦‚æœåªæœ‰__data__å†…çš„æ•°æ®å€¼å’Œç±»å‹æç¤ºï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸åˆ é™¤ä»»ä½•å†…å®¹
                    if data_value_occurrences and type_hint_occurrences and not top_level_occurrences:
                        # print(f"âœ… ä¿ç•™ {base_key} çš„æ•°æ®å€¼å’Œç±»å‹æç¤º - è¿™æ˜¯æ­£å¸¸é…ç½®ç»“æ„")
                        pass
                    elif data_value_occurrences and type_hint_occurrences and top_level_occurrences:
                        # print(f"âœ… ä¿ç•™ {base_key} çš„æ•°æ®å€¼å’Œç±»å‹æç¤ºï¼Œåˆ é™¤é¡¶å±‚é‡å¤")
                        pass
                    
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«YAMLé”šç‚¹åˆ«åæ ‡è®°
                has_anchor_alias = False
                for line_no, indent, section, key in occurrences:
                    line_content = lines[line_no].strip()
                    if '&' in line_content or '*' in line_content:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„YAMLé”šç‚¹æˆ–åˆ«åæ ‡è®°
                        import re
                        if re.search(r'&\w+|:\s*\*\w+', line_content):
                            has_anchor_alias = True
                            print(f"ğŸ” æ£€æµ‹åˆ°é”šç‚¹åˆ«åæ ‡è®°: {line_content.strip()} (ç¬¬{line_no+1}è¡Œ)")
                            break
                
                if not has_anchor_alias:
                    # éé”šç‚¹åˆ«åé‡å¤ï¼Œä¸åˆ é™¤ï¼Œå¯èƒ½æœ‰ç‰¹æ®Šç”¨é€”
                    print(f"ğŸ›¡ï¸  ä¿ç•™éé”šç‚¹åˆ«åé‡å¤é”®: '{base_key}' - å¯èƒ½æœ‰ç‰¹æ®Šç”¨é€”")
                    continue
                
                # åªæœ‰æ£€æµ‹åˆ°é”šç‚¹åˆ«åæ ‡è®°æ‰è¿›è¡Œé‡å¤åˆ é™¤
                print(f"ğŸ¯ å¤„ç†é”šç‚¹åˆ«åé‡å¤é”®: '{base_key}'")
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ __data__ å†…éƒ¨å’Œé¡¶å±‚çš„é‡å¤
                data_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                  if section == '__data__' and indent > 0]
                top_level_occurrences = [(line_no, indent, section, key) for line_no, indent, section, key in occurrences 
                                       if indent == 0 and section != '__data__']
                
                if data_occurrences and top_level_occurrences:
                    # __data__å†…éƒ¨å’Œé¡¶å±‚éƒ½æœ‰é”šç‚¹åˆ«åï¼š
                    # 1. å¤„ç†__data__å†…éƒ¨çš„é”šç‚¹å®šä¹‰ï¼šå»æ‰&id001æ ‡è®°ï¼Œä¿ç•™æ•°æ®
                    # 2. åˆ é™¤é¡¶å±‚çš„åˆ«åå¼•ç”¨*id001
                    
                    # å¤„ç†__data__å†…éƒ¨çš„é”šç‚¹å®šä¹‰
                    for line_no, indent, section, key in data_occurrences:
                        line_content = lines[line_no]
                        if '&' in line_content:
                            # å»æ‰é”šç‚¹æ ‡è®° &id001ï¼Œä¿ç•™æ•°æ®
                            import re
                            cleaned_line = re.sub(r'\s*&\w+', '', line_content)
                            lines[line_no] = cleaned_line
                            # print(f"ğŸ”§ æ¸…ç†__data__å†…é”šç‚¹æ ‡è®°: ç¬¬{line_no+1}è¡Œ å»æ‰&æ ‡è®°ï¼Œä¿ç•™æ•°æ®")
                    
                    # åˆ é™¤é¡¶å±‚çš„åˆ«åå¼•ç”¨
                    for line_no, indent, section, key in top_level_occurrences:
                        lines_to_remove.add(line_no)
                        self._mark_key_block_for_removal(lines, line_no, indent, lines_to_remove)
                        # print(f"âŒ åˆ é™¤é¡¶å±‚åˆ«åå¼•ç”¨: {key} (ç¬¬{line_no+1}è¡Œ) - åˆ é™¤*id001å¼•ç”¨")
                
                elif len(occurrences) > 1:
                    # é”šç‚¹åˆ«åè·¯å¾„é‡å¤å¤„ç†ï¼š
                    # 1. ä¿ç•™ç¬¬1ä¸ªï¼ˆé”šç‚¹å®šä¹‰&id001ï¼‰ï¼Œä½†å»æ‰&id001æ ‡è®°  
                    # 2. åˆ é™¤ç¬¬2ä¸ªåŠåç»­ï¼ˆåˆ«åå¼•ç”¨*id001ï¼‰
                    sorted_occurrences = sorted(occurrences, key=lambda x: x[0])  # æŒ‰è¡Œå·æ’åº
                    
                    # å¤„ç†ç¬¬1ä¸ªï¼ˆé”šç‚¹å®šä¹‰ï¼‰ï¼šå»æ‰&id001æ ‡è®°ï¼Œä¿ç•™æ•°æ®
                    first_line_no = sorted_occurrences[0][0]
                    first_line = lines[first_line_no]
                    if '&' in first_line:
                        # å»æ‰é”šç‚¹æ ‡è®° &id001ï¼Œä¿ç•™æ•°æ®
                        import re
                        cleaned_line = re.sub(r'\s*&\w+', '', first_line)
                        lines[first_line_no] = cleaned_line
                        # print(f"ğŸ”§ æ¸…ç†é”šç‚¹æ ‡è®°: ç¬¬{first_line_no+1}è¡Œ å»æ‰&æ ‡è®°ï¼Œä¿ç•™æ•°æ®")
                    
                    # åˆ é™¤ç¬¬2ä¸ªåŠåç»­ï¼ˆåˆ«åå¼•ç”¨ï¼‰
                    for line_no, indent, section, key in sorted_occurrences[1:]:
                        lines_to_remove.add(line_no)
                        self._mark_key_block_for_removal(lines, line_no, indent, lines_to_remove)
                        # print(f"âŒ åˆ é™¤åˆ«åå¼•ç”¨: {key} åœ¨è·¯å¾„ '{full_key_path}' (ç¬¬{line_no+1}è¡Œ) - åˆ é™¤*id001å¼•ç”¨")
            
            # if not is_test_mode:
            #     print(f"ğŸ”§ æ ‡è®°åˆ é™¤ {len(lines_to_remove)} è¡Œ: {sorted(lines_to_remove)}")
            
            # åˆ é™¤æ ‡è®°çš„è¡Œ
            if lines_to_remove:
                filtered_lines = [line for i, line in enumerate(lines) if i not in lines_to_remove]
                
                # å†™å›æ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(filtered_lines)
                
                # if not is_test_mode:
                #     print(f"âœ… æˆåŠŸåˆ é™¤ {len(lines_to_remove)} è¡Œé‡å¤å†…å®¹")
            else:
                # if not is_test_mode:
                #     print(f"â„¹ï¸  æ²¡æœ‰å‘ç°éœ€è¦åˆ é™¤çš„é‡å¤é”®")
                pass
                
        except Exception as e:
            # print(f"âŒ åˆ é™¤é‡å¤é”®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    def _mark_key_block_for_removal(self, lines: list, start_line: int, base_indent: int, lines_to_remove: set) -> None:
        """æ ‡è®°ä¸€ä¸ªé”®å€¼å¯¹å—çš„æ‰€æœ‰è¡Œä¸ºéœ€è¦åˆ é™¤"""
        lines_to_remove.add(start_line)
        
        # æ£€æŸ¥åç»­è¡Œæ˜¯å¦å±äºè¿™ä¸ªé”®å€¼å¯¹ï¼ˆæ›´æ·±çš„ç¼©è¿›æˆ–ç»­è¡Œï¼‰
        for i in range(start_line + 1, len(lines)):
            line = lines[i]
            stripped_line = line.strip()
            
            # ç©ºè¡Œä¹Ÿå¯èƒ½å±äºè¿™ä¸ªå—
            if not stripped_line:
                lines_to_remove.add(i)
                continue
            
            # æ³¨é‡Šè¡Œå¯èƒ½å±äºè¿™ä¸ªå—
            if stripped_line.startswith('#'):
                lines_to_remove.add(i)
                continue
            
            # è®¡ç®—ç¼©è¿›
            current_indent = len(line) - len(line.lstrip())
            
            # å¦‚æœç¼©è¿›æ›´æ·±ï¼Œè¯´æ˜æ˜¯è¿™ä¸ªé”®çš„å€¼çš„ä¸€éƒ¨åˆ†
            if current_indent > base_indent:
                lines_to_remove.add(i)
            else:
                # ç¼©è¿›ç›¸åŒæˆ–æ›´å°‘ï¼Œè¯´æ˜è¿™ä¸ªé”®å€¼å¯¹å—ç»“æŸäº†
                break
    
    def _try_reload_original_data(self, config_path: str):
        """å°è¯•é‡æ–°åŠ è½½åŸå§‹æ•°æ®ï¼ˆç”¨äºè·¯å¾„å˜åŒ–çš„æƒ…å†µï¼‰"""
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                    # å¤„ç†Windowsè·¯å¾„ä¸­çš„åæ–œæ è½¬ä¹‰é—®é¢˜
                    import re
                    def fix_windows_path(match):
                        path = match.group(1)
                        fixed_path = path.replace('\\\\', '/').replace('\\', '/')
                        return f'"{fixed_path}"'
                    
                    content = re.sub(r'"([a-zA-Z]:[\\\\][^"]*)"', fix_windows_path, content)
                    content = re.sub(r'"([\\\\][^"]*)"', fix_windows_path, content)
                    content = re.sub(r'"(\.[\\\\][^"]*)"', fix_windows_path, content)
                    
                    # åŠ è½½YAMLæ•°æ®
                    loaded_data = self._yaml.load(content) or {}
                    
                    # æ›´æ–°åŸå§‹æ•°æ®å’Œè·¯å¾„
                    self._original_yaml_data = loaded_data
                    self._config_path = config_path
                    
        except Exception as e:
            print(f"é‡æ–°åŠ è½½åŸå§‹æ•°æ®å¤±è´¥: {str(e)}")

    def get_backup_path(self, config_path: str, base_time: datetime, config_manager=None) -> str:
        """è·å–å¤‡ä»½è·¯å¾„ï¼ŒåŸºäºç»™å®šæ—¶é—´ç”Ÿæˆæ—¶é—´æˆ³
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            base_time: åŸºå‡†æ—¶é—´
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: å¤‡ä»½æ–‡ä»¶è·¯å¾„
        """
        date_str = base_time.strftime('%Y%m%d')
        time_str = base_time.strftime('%H%M%S')

        config_name = os.path.basename(config_path)
        name_without_ext = os.path.splitext(config_name)[0]

        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼šfilename_yyyymmdd_HHMMSS.yaml
        backup_filename = f"{name_without_ext}_{date_str}_{time_str}.yaml"

        # å°è¯•ä½¿ç”¨config.paths.backup_dirï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ä¼ ç»Ÿè·¯å¾„
        if config_manager:
            try:
                backup_dir = config_manager.get('paths.backup_dir')
                if backup_dir:
                    backup_path = os.path.join(backup_dir, backup_filename)
                    return backup_path
            except (AttributeError, KeyError):
                # å¦‚æœè·å–backup_dirå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
                pass
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šç”Ÿæˆå¤‡ä»½ç›®å½•ç»“æ„ï¼šåŸç›®å½•/backup/yyyymmdd/HHMMSS/
        config_dir = os.path.dirname(config_path)
        backup_dir = os.path.join(config_dir, 'backup', date_str, time_str)
        backup_path = os.path.join(backup_dir, backup_filename)
        return backup_path

    def _validate_yaml_types(self, data: Dict[str, Any], config_path: str) -> None:
        """éªŒè¯YAMLæ•°æ®çš„ç±»å‹æ­£ç¡®æ€§ï¼Œç¡®ä¿ä¸¥æ ¼åŒºåˆ†å­—ç¬¦ä¸²å’Œæ•°å­—
        
        Args:
            data: åŠ è½½çš„YAMLæ•°æ®
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Raises:
            TypeError: å½“å‘ç°ç±»å‹ä¸ä¸€è‡´æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        try:
            self._validate_data_recursive(data, config_path, "")
        except Exception as e:
            raise TypeError(f"é…ç½®æ–‡ä»¶ {config_path} ç±»å‹éªŒè¯å¤±è´¥: {str(e)}")
    
    def _validate_data_recursive(self, data: Any, config_path: str, path: str) -> None:
        """é€’å½’éªŒè¯æ•°æ®ç±»å‹
        
        Args:
            data: è¦éªŒè¯çš„æ•°æ®
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            path: å½“å‰éªŒè¯è·¯å¾„
        """
        if isinstance(data, dict):
            for key, value in data.items():
                current_path = f"{path}.{key}" if path else key
                # å¯¹äº__data__é”®ï¼Œéœ€è¦ç»§ç»­éªŒè¯å…¶å†…å®¹ï¼Œä½†è·³è¿‡å…¶ä»–å†…éƒ¨é”®
                # ç¡®ä¿keyæ˜¯å­—ç¬¦ä¸²ç±»å‹æ‰è°ƒç”¨startswith
                if isinstance(key, str) and key.startswith('__') and key != '__data__':
                    continue
                self._validate_data_recursive(value, config_path, current_path)
        elif isinstance(data, list):
            for i, item in enumerate(data):
                current_path = f"{path}[{i}]"
                self._validate_data_recursive(item, config_path, current_path)
        else:
            # å¯¹åŸºç¡€ç±»å‹è¿›è¡ŒéªŒè¯
            self._validate_basic_type(data, config_path, path)
    
    def _validate_basic_type(self, value: Any, config_path: str, path: str) -> None:
        """éªŒè¯åŸºç¡€ç±»å‹çš„æ­£ç¡®æ€§ - å·²ç¦ç”¨éªŒè¯ï¼ŒåŠ å¼•å·çš„å°±æ˜¯å­—ç¬¦ä¸²ï¼ŒåŸæ ·å¤„ç†
        
        Args:
            value: è¦éªŒè¯çš„å€¼
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            path: å½“å‰éªŒè¯è·¯å¾„
        """
        # ç§»é™¤ç±»å‹éªŒè¯é€»è¾‘ï¼ŒåŠ å¼•å·çš„å°±æ˜¯å­—ç¬¦ä¸²ï¼ŒåŸæ ·å¤„ç†
        pass